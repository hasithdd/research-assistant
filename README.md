<div align="center">

# ğŸ”¬ Research Assistant

**AI-powered research paper analysis with RAG-based Q&A**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-00a393.svg)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18+-61dafb.svg)](https://reactjs.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Upload research papers, get AI-generated structured summaries, and chat with your documents using semantic search powered by Qdrant and sentence-transformers.

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [API](#-api-endpoints) â€¢ [Development](#-development)

</div>

---

## âœ¨ Features

- ğŸ“„ **PDF Upload & Parsing** â€“ Extract text from research papers with OCR fallback
- ğŸ¤– **AI Summarization** â€“ Generate structured summaries with key findings
- ğŸ’¬ **RAG-based Chat** â€“ Ask questions and get contextual answers from your papers
- ğŸ” **Semantic Search** â€“ Qdrant vector store with sentence-transformers embeddings
- âš¡ **Fast Startup** â€“ Models preloaded on container boot, HF cache persisted
- ğŸ³ **Docker Ready** â€“ Full stack deployment with Docker Compose

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚ â”€â”€â”€> â”‚   Backend    â”‚ â”€â”€â”€> â”‚   Qdrant    â”‚
â”‚  (React +   â”‚ HTTP â”‚  (FastAPI)   â”‚      â”‚ Vector DB   â”‚
â”‚   Vite)     â”‚ <â”€â”€â”€ â”‚              â”‚ <â”€â”€â”€ â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Hugging Face â”‚
                     â”‚  Embeddings  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tech Stack:**
- **Backend:** FastAPI, Python 3.12, SentenceTransformers, PyMuPDF, PDFPlumber
- **Vector Store:** Qdrant
- **Frontend:** React 18, TypeScript, Vite, TailwindCSS
- **AI:** OpenAI GPT (summarization), sentence-transformers/all-MiniLM-L6-v2 (embeddings)

## ğŸš€ Quick Start

### Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/hasithdd/research-assistant.git
cd research-assistant

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# Launch all services
docker compose up -d --build

# Access the application
# Frontend: http://localhost:5173
# Backend:  http://localhost:8000
# API Docs: http://localhost:8000/docs
```

The backend container mounts `~/.cache/huggingface` to persist downloaded models across restarts.

### Health Check

```bash
curl http://localhost:8000/health
# {"status":"ok"}
```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```bash
# Required
OPENAI_API_KEY=sk-...

# Optional
HF_TOKEN=hf_...                                          # Speeds up model downloads
QDRANT_URL=http://qdrant:6333                           # Vector store endpoint
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `POST` | `/upload/pdf` | Upload PDF, returns `paper_id` and summary |
| `POST` | `/chat/` | Chat with a paper (requires `paper_id` and `query`) |
| `GET` | `/summary/{paper_id}` | Retrieve cached summary |

**Interactive API Documentation:** http://localhost:8000/docs

### Example: Upload & Chat

```bash
# Upload a paper
curl -X POST http://localhost:8000/upload/pdf \
  -F "file=@paper.pdf"
# Response: {"paper_id": "abc-123", "summary": {...}}

# Chat with the paper
curl -X POST http://localhost:8000/chat/ \
  -H "Content-Type: application/json" \
  -d '{"paper_id": "abc-123", "query": "What is the main contribution?"}'
```

## ğŸ’» Development

### Prerequisites

- Python 3.12+
- Node.js 18+
- Docker & Docker Compose (for containerized setup)
- System packages: `tesseract-ocr`, `poppler-utils` (if running backend locally)

### Local Backend Setup

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Start Qdrant (if not using Docker)
docker run -d -p 6333:6333 qdrant/qdrant:latest

# Run backend
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Local Frontend Setup

```bash
cd frontend
npm install
VITE_API_BASE_URL=http://localhost:8000 npm run dev
# Dev server: http://localhost:5173
```

### Running Tests

```bash
# Backend tests
pytest

# Frontend tests (if configured)
cd frontend && npm test
```

### Code Quality

```bash
# Linting & formatting (backend)
ruff check backend/ --fix
ruff format backend/

# Pre-commit hooks
pre-commit install
pre-commit run --all-files
```

## ğŸ› Troubleshooting

### NumPy/PyTorch compatibility error
```
A module that was compiled using NumPy 1.x cannot be run in NumPy 2.x
```
**Solution:** `numpy<2` is pinned in `requirements.txt`. Rebuild Docker images:
```bash
docker compose build --no-cache backend
```

### Slow first request
The embedding model downloads on startup. With Docker, the HF cache volume (`~/.cache/huggingface`) prevents re-downloads on container restarts.

### Port conflicts
If ports 8000, 5173, or 6333 are in use:
```bash
# Edit docker-compose.yml to change port mappings
ports:
  - "8001:8000"  # Map to different host port
```

## ğŸ“¦ Project Structure

```
research-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/           # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ services/      # Business logic (RAG, PDF parsing, vectorstore)
â”‚   â”‚   â”œâ”€â”€ models/        # Pydantic schemas
â”‚   â”‚   â””â”€â”€ core/          # Config, settings
â”‚   â”œâ”€â”€ tests/             # Pytest test suite
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ pages/         # Page layouts
â”‚   â”‚   â””â”€â”€ api/           # API client
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Qdrant](https://qdrant.tech/) - Vector similarity search engine
- [Sentence Transformers](https://www.sbert.net/) - State-of-the-art embeddings
- [OpenAI](https://openai.com/) - GPT-based summarization

---

<div align="center">
Made with â¤ï¸ by <a href="https://github.com/hasithdd">hasithdd</a>
</div>
